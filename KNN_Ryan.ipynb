{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import preprocessing # for label encoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "We read the data from a local csv file and construct our matrix of feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = pd.read_csv(\"data\\play_by_play_2019.csv\", dtype=object) # maybe should be dtype=str\n",
    "data = data_orig.copy()\n",
    "\n",
    "# Get rid of data after week 19\n",
    "data = data.loc[data[\"week\"].astype(\"int\") < 19]\n",
    "\n",
    "# Subtract 1 from each week date so that we match the elos csv\n",
    "#data[\"week\"] = data[\"week\"].apply(lambda x: str(int(x) - 1))\n",
    "\n",
    "\n",
    "# Trim up our data to only features we care about ( we'll add elo's later)\n",
    "feature_vectors = data[[\"touchdown\", \"season_type\", \"yardline_100\", \"quarter_seconds_remaining\", \"half_seconds_remaining\",\n",
    "                 \"game_seconds_remaining\", \"game_half\", \"drive\", \"sp\", \"qtr\", \"down\", \"goal_to_go\", \"ydstogo\", \"play_type\", \"rush_attempt\", \"pass_attempt\",\n",
    "                            \"td_prob\"]]\n",
    "# Once I get to a certain point, I should try adding data from other csv files to this dataframe as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell I should add ELO ratings to each row in the data.  \n",
    "# Going to skip that for now and just do this with data we already have\n",
    "# Weird inconsitency between elo vals and actual data - quick hack might be to just\n",
    "# add an elo of 1500 where we can't find one....\n",
    "\n",
    "with open(\"eloVals.json\") as file:\n",
    "    elos = json.load(file)\n",
    "\n",
    "home_off_elo = []\n",
    "home_def_elo = []\n",
    "away_off_elo = []\n",
    "away_def_elo = []\n",
    "\n",
    "YEAR = 2019\n",
    "\n",
    "#print(feature_vectors.shape)\n",
    "# Loop through rows\n",
    "for i in range(data.shape[0]):\n",
    "    # Tricky Part --> if we're getting the elos going into a game for a team, and they didn't play\n",
    "    #                  the week before, we have to get the elo from the game two weeks ago\n",
    "    # \n",
    "    # The try except blocks are a bit of a hack but they works!\n",
    "    try:\n",
    "        home_off_elo.append(elos[data[\"home_team\"].iloc[i]][str(YEAR)][str(int(data[\"week\"].iloc[i]) - 1)][\"off\"])\n",
    "    except KeyError:\n",
    "        home_off_elo.append(elos[data[\"home_team\"].iloc[i]][str(YEAR)][str(int(data[\"week\"].iloc[i]) - 2)][\"off\"])\n",
    "        \n",
    "    try:\n",
    "        home_def_elo.append(elos[data[\"home_team\"].iloc[i]][str(YEAR)][str(int(data[\"week\"].iloc[i]) - 1)][\"def\"])\n",
    "    except KeyError:\n",
    "        home_def_elo.append(elos[data[\"home_team\"].iloc[i]][str(YEAR)][str(int(data[\"week\"].iloc[i]) - 2)][\"def\"])\n",
    "        \n",
    "    try:\n",
    "        away_off_elo.append(elos[data[\"away_team\"].iloc[i]][str(YEAR)][str(int(data[\"week\"].iloc[i]) - 1)][\"off\"])\n",
    "    except KeyError:\n",
    "        away_off_elo.append(elos[data[\"away_team\"].iloc[i]][str(YEAR)][str(int(data[\"week\"].iloc[i]) - 2)][\"off\"])\n",
    "        \n",
    "    try:\n",
    "        away_def_elo.append(elos[data[\"away_team\"].iloc[i]][str(YEAR)][str(int(data[\"week\"].iloc[i]) - 1)][\"def\"])\n",
    "    except KeyError:\n",
    "        away_def_elo.append(elos[data[\"away_team\"].iloc[i]][str(YEAR)][str(int(data[\"week\"].iloc[i]) - 2)][\"def\"])\n",
    "        \n",
    "# Now we can add these elo arrays to our feature_vectors dataframe as columns\n",
    "feature_vectors[\"home_off_elo\"] = home_off_elo\n",
    "feature_vectors[\"home_def_elo\"] = home_def_elo\n",
    "feature_vectors[\"away_off_elo\"] = away_off_elo\n",
    "feature_vectors[\"away_def_elo\"] = away_def_elo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data\n",
    "Need to clean up the data so it can be processed by the KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Delete all columns that have bad plays (i.e. kickoffs, field goals)\n",
    "feature_vectors = feature_vectors[feature_vectors.yardline_100.notnull()]\n",
    "feature_vectors = feature_vectors[feature_vectors.down.notnull()]\n",
    "feature_vectors = feature_vectors[feature_vectors.play_type.notnull()]\n",
    "\n",
    "# Go through and fill in missing values for the columns that initially had NA values\n",
    "#feature_vectors[\"down\"] = feature_vectors[\"down\"].fillna(-1)\n",
    "#feature_vectors[\"play_type\"] = feature_vectors[\"play_type\"].fillna(\"yikes\")\n",
    "#feature_vectors[\"rush_attempt\"] = feature_vectors[\"rush_attempt\"].fillna(-1)\n",
    "#feature_vectors[\"pass_attempt\"] = feature_vectors[\"pass_attempt\"].fillna(-1)\n",
    "#print(feature_vectors[\"play_type\"])\n",
    "\n",
    "# Encode columns in feature_vectors so that there aren't any strings \n",
    "le = preprocessing.LabelEncoder()\n",
    "feature_vectors[\"season_type\"] = le.fit_transform(feature_vectors[\"season_type\"])\n",
    "feature_vectors[\"game_half\"] = le.fit_transform(feature_vectors[\"game_half\"])\n",
    "feature_vectors[\"play_type\"] = le.fit_transform(feature_vectors[\"play_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and test data\n",
    "train_data, test_data = train_test_split(feature_vectors, test_size=0.2, random_state=35, shuffle=True)\n",
    "\n",
    "train_labels = train_data[[\"touchdown\"]]\n",
    "test_labels = test_data[[\"touchdown\"]]\n",
    "\n",
    "train_data = train_data.drop(\"touchdown\", 1)\n",
    "test_data = test_data.drop(\"touchdown\", 1)\n",
    "\n",
    "#print(test_data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "model.fit(train_data, train_labels.values.ravel())\n",
    "predicted = model.predict(test_data)\n",
    "\n",
    "# predicted is a ndarray while test_labels is a DataFrame\n",
    "#print(\"Predicted: \", predicted[100:150])\n",
    "#print(\"Actual Labels: \", test_labels.iloc[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy\n",
    "Compare predicted with test labels and output the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length predicted:  (7753,)\n",
      "shape actual labels:  (7753, 1)\n",
      "General Accuracy of model on test data:  0.9650457887269444\n",
      "Accuracy on touchdowns:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"length predicted: \", predicted.shape)\n",
    "print(\"shape actual labels: \", test_labels.shape)\n",
    "\n",
    "test_labels_arr = test_labels.values.ravel() # Convert our test labels into a flat array\n",
    "assert len(predicted) == len(test_labels_arr), \"Predictions and test labels should have same len\"\n",
    "\n",
    "matches = 0\n",
    "\n",
    "num_touchdowns = 0\n",
    "correctly_pred_touchdowns = 0\n",
    "\n",
    "for i in range(0, len(predicted)):\n",
    "    if predicted[i] == test_labels_arr[i]:\n",
    "        matches += 1\n",
    "    \n",
    "    if test_labels_arr[i] == '1':\n",
    "        num_touchdowns += 1\n",
    "        \n",
    "    if test_labels_arr[i] == '1' and predicted[i] == '1':\n",
    "        correctly_pred_touchdowns += 1\n",
    "        \n",
    "gen_accuracy = matches / len(predicted)\n",
    "td_accuracy = correctly_pred_touchdowns / num_touchdowns\n",
    "\n",
    "print(\"General Accuracy of model on test data: \", gen_accuracy)\n",
    "\n",
    "print(\"Accuracy on touchdowns: \", td_accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
