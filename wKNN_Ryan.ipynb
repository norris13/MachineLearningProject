{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing # for label encoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "We read the data from a local csv file and construct our matrix of feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = pd.read_csv(\"data\\play_by_play_2019.csv\", dtype=object) # maybe should be dtype=str\n",
    "# Trim up our data to only features we care about\n",
    "feature_vectors = data_orig[[\"touchdown\", \"home_team\", \"away_team\", \"season_type\", \"yardline_100\", \"quarter_seconds_remaining\", \"half_seconds_remaining\",\n",
    "                 \"game_seconds_remaining\", \"game_half\", \"drive\", \"sp\", \"qtr\", \"down\", \"goal_to_go\", \"ydstogo\", \"play_type\", \"rush_attempt\", \"pass_attempt\" ]]\n",
    "# Once I get to a certain point, I should try adding data from other csv files to this dataframe as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell I should add ELO ratings to each row in the data.  \n",
    "# Going to skip that for now and just do this with data we already have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data\n",
    "Need to clean up the data so it can be processed by the KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Delete all columns that have bad plays (i.e. kickoffs, field goals)\n",
    "feature_vectors = feature_vectors[feature_vectors.yardline_100.notnull()]\n",
    "feature_vectors = feature_vectors[feature_vectors.down.notnull()]\n",
    "feature_vectors = feature_vectors[feature_vectors.play_type.notnull()]\n",
    "\n",
    "# Go through and fill in missing values for the columns that initially had NA values\n",
    "#feature_vectors[\"down\"] = feature_vectors[\"down\"].fillna(-1)\n",
    "#feature_vectors[\"play_type\"] = feature_vectors[\"play_type\"].fillna(\"yikes\")\n",
    "#feature_vectors[\"rush_attempt\"] = feature_vectors[\"rush_attempt\"].fillna(-1)\n",
    "#feature_vectors[\"pass_attempt\"] = feature_vectors[\"pass_attempt\"].fillna(-1)\n",
    "#print(feature_vectors[\"play_type\"])\n",
    "\n",
    "# Encode columns in feature_vectors so that there aren't any strings \n",
    "le = preprocessing.LabelEncoder()\n",
    "feature_vectors[\"home_team\"] = le.fit_transform(feature_vectors[\"home_team\"])\n",
    "feature_vectors[\"away_team\"] = le.fit_transform(feature_vectors[\"away_team\"])\n",
    "feature_vectors[\"season_type\"] = le.fit_transform(feature_vectors[\"season_type\"])\n",
    "feature_vectors[\"game_half\"] = le.fit_transform(feature_vectors[\"game_half\"])\n",
    "feature_vectors[\"play_type\"] = le.fit_transform(feature_vectors[\"play_type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and test data\n",
    "train_data, test_data = train_test_split(feature_vectors, test_size=0.2, random_state=35, shuffle=True)\n",
    "\n",
    "train_labels = train_data[[\"touchdown\"]]\n",
    "test_labels = test_data[[\"touchdown\"]]\n",
    "\n",
    "train_data = train_data.drop(\"touchdown\", 1)\n",
    "test_data = test_data.drop(\"touchdown\", 1)\n",
    "\n",
    "#print(test_data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "model.fit(train_data, train_labels.values.ravel())\n",
    "predicted = model.predict(test_data)\n",
    "\n",
    "# predicted is a ndarray while test_labels is a DataFrame\n",
    "#print(\"Predicted: \", predicted[100:150])\n",
    "#print(\"Actual Labels: \", test_labels.iloc[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy\n",
    "Compare predicted with test labels and output the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
